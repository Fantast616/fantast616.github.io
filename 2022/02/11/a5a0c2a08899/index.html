<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.fantast.top","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","width":250,"display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"manual"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="整理了一些不同任务中常见的Loss损失函数\信息熵、交叉熵、相对熵以及相关的基础知识内容。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习基础系列笔记17——常见的Loss损失函数整理">
<meta property="og:url" content="https://blog.fantast.top/2022/02/11/a5a0c2a08899/index.html">
<meta property="og:site_name" content="Fantast&#39;s Blog">
<meta property="og:description" content="整理了一些不同任务中常见的Loss损失函数\信息熵、交叉熵、相对熵以及相关的基础知识内容。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://www.zhihu.com/equation?tex=z%3D+wx%2Bb">
<meta property="og:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_15_642.png">
<meta property="og:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_12_56.png">
<meta property="og:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_04_33_822.png">
<meta property="og:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_05_00_718.png">
<meta property="article:published_time" content="2022-02-11T14:18:19.000Z">
<meta property="article:modified_time" content="2022-08-07T14:46:29.000Z">
<meta property="article:author" content="Fantast">
<meta property="article:tag" content="Loss Function">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.zhihu.com/equation?tex=z%3D+wx%2Bb">


<link rel="canonical" href="https://blog.fantast.top/2022/02/11/a5a0c2a08899/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://blog.fantast.top/2022/02/11/a5a0c2a08899/","path":"2022/02/11/a5a0c2a08899/","title":"机器学习基础系列笔记17——常见的Loss损失函数整理"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习基础系列笔记17——常见的Loss损失函数整理 | Fantast's Blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Fantast's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Fantast's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E5%A4%9A%E7%B1%BB%E5%88%AB%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1%E4%BF%A1%E6%81%AF%E7%86%B5%E4%BA%A4%E5%8F%89%E7%86%B5%E7%9B%B8%E5%AF%B9%E7%86%B5%E7%9A%84%E6%A6%82%E5%BF%B5%E4%B8%8E%E5%BA%94%E7%94%A8"><span class="nav-text">一、多类别分类任务常用损失：信息熵、交叉熵、相对熵的概念与应用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BF%A1%E6%81%AF%E7%86%B5"><span class="nav-text">1、信息熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%9B%B8%E5%AF%B9%E7%86%B5"><span class="nav-text">2、相对熵</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="nav-text">3、交叉熵：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BD%BF%E7%94%A8%E4%BA%A4%E5%8F%89%E7%86%B5"><span class="nav-text">4、为什么使用交叉熵：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E5%A4%9A%E6%A0%87%E7%AD%BE%E5%88%86%E7%B1%BB%E4%BB%BB%E5%8A%A1"><span class="nav-text">二、多标签分类任务：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E5%9B%9E%E5%BD%92%E4%BB%BB%E5%8A%A1%E5%B8%B8%E7%94%A8%E6%8D%9F%E5%A4%B1"><span class="nav-text">三、回归任务常用损失：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#l1-loss-%E5%B9%B3%E5%9D%87%E7%BB%9D%E5%AF%B9%E8%AF%AF%E5%B7%AE"><span class="nav-text">1、L1 Loss 平均绝对误差</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#l2-loss-%E5%9D%87%E6%96%B9%E8%AF%AF%E5%B7%AEmse"><span class="nav-text">3、L2 Loss 均方误差MSE</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#smooth-l1-loss"><span class="nav-text">3、Smooth L1 Loss</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fantast"
      src="/images/avatar.webp">
  <p class="site-author-name" itemprop="name">Fantast</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">42</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">98</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fantast416" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fantast416" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fantast416@gmail.com" title="E-Mail → mailto:fantast416@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.zhihu.com/people/shuo-shuo-3-41" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;shuo-shuo-3-41" rel="noopener" target="_blank">ZhiHu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.next.zju.edu.cn/" title="http:&#x2F;&#x2F;www.next.zju.edu.cn&#x2F;" rel="noopener" target="_blank">NextLab</a>
        </li>
    </ul>
  </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.fantast.top/2022/02/11/a5a0c2a08899/">
    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.webp">
      <meta itemprop="name" content="Fantast">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fantast's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习基础系列笔记17——常见的Loss损失函数整理
        </h1>

        <div class="post-meta-container">
          
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-02-11 22:18:19" itemprop="dateCreated datePublished" datetime="2022-02-11T22:18:19+08:00">2022-02-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-08-07 22:46:29" itemprop="dateModified" datetime="2022-08-07T22:46:29+08:00">2022-08-07</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E2%93%B5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">⓵ 深度学习笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E2%93%B5-%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/Basic%E7%B3%BB%E5%88%97%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">Basic系列笔记</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>2.2k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>6 分钟</span>
    </span>
</div>

            <div class="post-description">整理了一些不同任务中常见的Loss损失函数\信息熵、交叉熵、相对熵以及相关的基础知识内容。</div>
            <div class="post-remind">Google Chrome is recommended, otherwise the image size may be wrong</div>
            <div class="post-remind">FireFox is not recommended,Because it does not support the image zoom property</div>
        </div>
        
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h3
id="一多类别分类任务常用损失信息熵交叉熵相对熵的概念与应用">一、多类别分类任务常用损失：信息熵、交叉熵、相对熵的概念与应用</h3>
<h4 id="信息熵">1、信息熵</h4>
<ol type="1">
<li>随机变量 <span class="math inline">\(x\)</span> 的自信息
(self-information)，描述的是随机变量的某个事件发生所带来的信息量。</li>
</ol>
<p>​ <span class="math inline">\(I(x) = -log(p(x))\)</span></p>
<ol start="2" type="1">
<li><strong>信息熵</strong>即所有信息量的期望,其中<span
class="math inline">\(n\)</span>为事件的所有可能性。</li>
</ol>
<figure>
<img
src="https://www.zhihu.com/equation?tex=H%28X%29%3D%E2%88%92%E2%88%91_xp%28x%29log%28p%28x%29%29%3D%E2%88%92%E2%88%91_%7Bi%3D1%7D%5Enp%28x_i%29log%28p%28x_i%29%29"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<h4 id="相对熵">2、相对熵</h4>
<p>​ KL散度，如果对于同一个随机变量x有两个单独的概率分布 <span
class="math inline">\(p(x)\)</span>和 <span
class="math inline">\(q(x)\)</span>，可以使用相对熵来衡量这两个分布的差异。</p>
<figure>
<img
src="https://www.zhihu.com/equation?tex=D_%7BKL%7D%28p%7C%7Cq%29%3D%5Csum_%7Bi%3D1%7D%5Enp%28x_i%29log%28%5Cfrac%7Bp%28x_i%29%7D%7Bq%28x_i%29%7D%29"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​
K-L散度其实是<strong>数据的原始分布p和近似分布q之间的对数差值的期望</strong>。</p>
<p>​ K-L散度<strong>并非距离，其不满足对称性</strong>，即 $D_{KL}(p||q) $
<span class="math inline">\(!=\)</span> $D_{KL}(q||p) $</p>
<h4 id="交叉熵">3、交叉熵：</h4>
<figure>
<img
src="https://www.zhihu.com/equation?tex=H%28p%2Cq%29%3D-%5Csum_%7Bi%3D1%7D%5Enp%28x_i%29log%28q%28x_i%29%29"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​ 在机器学习中，往往用 <span class="math inline">\(p(x)\)</span>
用来描述<strong>真实分布</strong>， <span
class="math inline">\(q(x)\)</span>
用来描述模型<strong>预测的分布</strong>。</p>
<p>​
计算损失，理应使用相对熵来计算概率分布的差异，然而由相对熵推导出的结果看：</p>
<p>​ 由于信息熵描述的是消除 p (即真实分布)
的不确定性所需信息量的度量，所以其值应该是最小的、固定的。那么：<strong>优化相对熵也就是优化交叉熵，所以在机器学习中使用交叉熵就可以了</strong></p>
<h4 id="为什么使用交叉熵">4、为什么使用交叉熵：</h4>
<p>​
在机器学习中，我们希望模型在训练数据上学到的<strong>预测数据分布</strong>与<strong>真实数据分布</strong>越相近越好，上面讲过了，用相对熵，但是为了简便计算使用交叉熵就可以了。</p>
<p>在二分类中，交叉熵损失函数如下：<span
class="math inline">\(y\)</span>是实际标签，<span
class="math inline">\(\hat y\)</span>
是预测值z经过sigmoid函数之后的预测概率。</p>
<figure>
<img
src="https://www.zhihu.com/equation?tex=L%3D-%5Bylog+\hat+y%2B(1-y)log+(1-\hat+y)%5D"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>Sigmoid函数如下：</p>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\sigma(z)+%3D+\frac%7B1%7D%7B1%2Be%5E%7B-z%7D%7D"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​
交叉熵损失函数一般用来代替均方差损失函数与sigmoid激活函数的组合：对于sigmoid函数，当
<span class="math inline">\(x\)</span>
的取值越大或越小，函数曲线变得越平缓，意味着导数<span
class="math inline">\(\sigma(x)&#39;\)</span>
越趋近于0。以单个样本的梯度下降为例子：</p>
<figure>
<img src="https://www.zhihu.com/equation?tex=z%3D+wx%2Bb"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\hat%7By%7D%3D+a+%3D\sigma(z)"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=L_1(y%2Ca)%3D\frac%7B1%7D%7B2%7D(y-a)%5E2"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=L_2%28y%2Ca%29%3D-%28ylog%28a%29%2B%281-y%29log%281-a%29%29"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​
前两个公式是前向传播过程中线性的部分，和非线性的部分。L1是MSE损失函数，L2是交叉熵损失函数。然后我们分别用L1和L2对参数w和b，利用链式法则求解梯度。</p>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_1(y%2Ca)%7D%7B\partial+w%7D%3D-%7Cy-\sigma(z)%7C\sigma&#39;(z)x"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_1(y%2Ca)%7D%7B\partial+b%7D%3D-%7Cy-\sigma(z)%7C\sigma&#39;(z)"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_2(y%2Ca)%7D%7B\partial+w%7D%3Dx%5B\sigma(z)-y%5D"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<figure>
<img
src="https://www.zhihu.com/equation?tex=\frac%7B\partial+L_2(y%2Ca)%7D%7B\partial+b%7D%3D\sigma(z)-y"
alt="[公式]" />
<figcaption aria-hidden="true">[公式]</figcaption>
</figure>
<p>​
可以看出，<strong>均方差</strong>对参数的偏导的结果都<strong>乘了sigmoid的导数</strong>
<span class="math inline">\(\sigma(z)&#39;\)</span>
，而之前看图发现sigmoid导数在其变量值很大或很小时趋近于0，所以偏导数很有可能接近于0。反观<strong>交叉熵</strong>对参数的偏导就<strong>没有sigmoid导数</strong>，所以不存在这个问题。<strong>这就是选择交叉熵而不选择均方差的原因。</strong></p>
<p><strong>分类任务的学习过程：</strong></p>
<p>​
用神经网络最后一层输出的情况，来看一眼整个模型预测、获得损失和学习的流程：</p>
<ol type="1">
<li>神经网络最后一层得到每个类别的得分<strong>scores（也叫logits）</strong>；</li>
<li>该得分经过<strong>sigmoid(或softmax)函数</strong>获得概率输出；</li>
<li>模型预测的类别概率输出与真实类别的one
hot形式进行交叉熵损失函数的计算。</li>
</ol>
<h3 id="二多标签分类任务">二、多标签分类任务：</h3>
<p>​
在多标签分类任务中，一般采用<strong>sigmoid</strong>作为输出层的激活函数，使用
binary_crossentropy（二分类交叉熵损失函数）作为损失函数. <span
class="math display">\[
\sigma(x) = \frac{1}{1 + e^{-x}}
\]</span> ​ 其中<span class="math inline">\(a\)</span>表示使用 sigmoid
函数激活输出层对应的神经元，<strong>此时最后一层的输出就不能看成一个分布了，因为加起来不为
1，现在把输出层每个神经元看作是一个二项分布，
这相当于将一个多标签问题转化为了在每个标签上的二分类问题。</strong></p>
<p>​ <img
src="https://www.zhihu.com/equation?tex=L_2(y%2Ca)%3D-(ylog(a)%2B(1-y)log(1-a))"
alt="[公式]" /></p>
<p>​ 计算一个样本各个标签的损失，然后取平均值，得到最后的损失。</p>
<h3 id="三回归任务常用损失">三、回归任务常用损失：</h3>
<h4 id="l1-loss-平均绝对误差">1、L1 Loss 平均绝对误差</h4>
<p>​ <strong>目标变量和预测变量之间绝对差值之和</strong></p>
<p>​ MAE曲线连续，但是在<em>y</em>−<em>f</em>(<em>x</em>)=0处不可导。而且
MAE
大部分情况下梯度都是相等的，这意味着即使对于小的损失值，其梯度也是大的。这不利于函数的收敛和模型的学习。但是，无论对于什么样的输入值，都有着稳定的梯度，不会导致梯度爆炸问题，具有较为稳健性的解。</p>
<p>​
MAE有个优点就是，对于离群点不那么敏感。因为MAE计算的是误差<em>y</em>−<em>f</em>(<em>x</em>)
的绝对值，对于任意大小的差值，其惩罚都是固定的。<strong>针对带有离群点的数据，MAE的效果要好于MSE。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_15_642.png" style="zoom:50%;" /></p>
<h4 id="l2-loss-均方误差mse">3、L2 Loss 均方误差MSE</h4>
<p>​
MSE的函数曲线光滑、连续，处处可导，便于使用梯度下降算法，是一种常用的损失函数。
而且，随着误差的减小，梯度也在减小，这有利于收敛，即使使用固定的学习速率，也能较快的收敛到最小值。</p>
<p>​ 当<span class="math inline">\(y\)</span>和<span
class="math inline">\(f(x)\)</span>也就是真实值和预测值的差值大于1时，会放大误差；而当差值小于1时，则会缩小误差，这是平方运算决定的。MSE对于较大的误差（&gt;1）给予较大的惩罚，较小的误差（&lt;1）给予较小的惩罚。也就是说，<strong>对离群点比较敏感，受其影响较大。</strong></p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_11_35_12_56.png" style="zoom:50%;" /></p>
<h4 id="smooth-l1-loss">3、Smooth L1 Loss</h4>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_04_33_822.png" style="zoom: 50%;" /></p>
<p>​
从下图种中可以看出，该函数实际是一个分段函数，既解决了L1不光滑的问题，也解决了L2容易产生梯度爆炸的问题。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/屏幕捕获_2022_02_12_12_05_00_718.png" style="zoom:50%;" /></p>
<p><strong>Smooth L1的优点</strong></p>
<ul>
<li>相比于L1损失函数，可以收敛得更快。</li>
<li>相比于L2损失函数，对离群点、异常值不敏感，梯度变化相对更小，训练时不容易跑飞。</li>
</ul>
<p><strong>参考：</strong></p>
<p>https://zhuanlan.zhihu.com/p/35709485</p>
<p>https://www.zhihu.com/question/336677048/answer/761385679</p>
<p>https://www.cnblogs.com/wangguchangqing/p/12021638.html</p>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Loss-Function/" rel="tag"># Loss Function</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/02/11/de2db590f015/" rel="prev" title="博文复习日志1">
                  <i class="fa fa-chevron-left"></i> 博文复习日志1
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/02/15/c20d8f810e24/" rel="next" title="机器学习基础系列笔记18——常见的位置编码Position Encoding方法">
                  机器学习基础系列笔记18——常见的位置编码Position Encoding方法 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fantast</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">769k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">35:35</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Fantast416/myblog-comment","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
