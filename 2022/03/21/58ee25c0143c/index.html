<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"blog.fantast.top","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.9.0","exturl":false,"sidebar":{"position":"left","width":250,"display":"always","padding":18,"offset":12},"copycode":true,"bookmark":{"enable":true,"color":"#222","save":"manual"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"utterances","storage":true,"lazyload":false,"nav":null,"activeClass":"utterances"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>
<meta name="description" content="提出了StyTr2，该框架中使用两个编码器来获取特定领域（Content &amp; Style）的信息。在编码器之后，使用Transformer解码器逐步生成输出序列。">
<meta property="og:type" content="article">
<meta property="og:title" content="《StyTr2 Unbiased Image Style Transfer with Transformers》">
<meta property="og:url" content="https://blog.fantast.top/2022/03/21/58ee25c0143c/index.html">
<meta property="og:site_name" content="Fantast&#39;s Blog">
<meta property="og:description" content="提出了StyTr2，该框架中使用两个编码器来获取特定领域（Content &amp; Style）的信息。在编码器之后，使用Transformer解码器逐步生成输出序列。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321224013009.png">
<meta property="article:published_time" content="2022-03-21T10:12:19.000Z">
<meta property="article:modified_time" content="2022-11-19T10:43:51.099Z">
<meta property="article:author" content="Fantast">
<meta property="article:tag" content="CNN">
<meta property="article:tag" content="Style Transfer">
<meta property="article:tag" content="Transformer">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321224013009.png">


<link rel="canonical" href="https://blog.fantast.top/2022/03/21/58ee25c0143c/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://blog.fantast.top/2022/03/21/58ee25c0143c/","path":"2022/03/21/58ee25c0143c/","title":"《StyTr2 Unbiased Image Style Transfer with Transformers》"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>《StyTr2 Unbiased Image Style Transfer with Transformers》 | Fantast's Blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="Fantast's Blog" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Fantast's Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E5%90%8D%E7%A7%B0stytr2-unbiased-image-style-transfer-with-transformers"><span class="nav-text">论文名称：《StyTr^2
Unbiased Image Style Transfer with Transformers》</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%AE%BA%E6%96%87%E5%9C%B0%E5%9D%80-httparxiv.orgabs2105.14576"><span class="nav-text">论文地址：
http:&#x2F;&#x2F;arxiv.org&#x2F;abs&#x2F;2105.14576</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B3%E9%94%AE%E8%AF%8D"><span class="nav-text">1、关键词：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%91%98%E8%A6%81"><span class="nav-text">2、摘要：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%A2%86%E5%9F%9F%E8%83%8C%E6%99%AFstyle-transfer"><span class="nav-text">3、领域背景—Style Transfer：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%88%E5%89%8D%E5%B7%A5%E4%BD%9C%E6%8F%8F%E8%BF%B0%E4%B8%8E%E6%AF%94%E8%BE%83"><span class="nav-text">4、先前工作描述与比较：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%BB%E8%A6%81%E8%AE%BE%E8%AE%A1%E6%80%9D%E6%83%B3"><span class="nav-text">5、主要设计思想：</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%85%B7%E4%BD%93%E6%96%B9%E6%B3%95%E4%B8%8E%E7%BD%91%E7%BB%9C%E6%9E%B6%E6%9E%84"><span class="nav-text">6、具体方法与网络架构：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2%E4%B8%BApatches-linear-embedding%E4%B8%8Evit%E7%B1%BB%E4%BC%BC"><span class="nav-text">1)
图像分割为Patches + Linear Embedding【与ViT类似】</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81content-aware-positional-encoding"><span class="nav-text">2) 位置编码（Content
Aware Positional Encoding）：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transformer-encoder"><span class="nav-text">3) Transformer Encoder：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#part1-content-image"><span class="nav-text">Part1: Content Image</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#part2-style-image"><span class="nav-text">Part2: Style Image：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#transformer-decoder"><span class="nav-text">4）Transformer Decoder：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#decoder"><span class="nav-text">5）Decoder：</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%87%87%E7%94%A8%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-text">7、采用的损失函数：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#content-percepture-loss-%E6%84%9F%E7%9F%A5%E5%86%85%E5%AE%B9%E6%8D%9F%E5%A4%B1-style-percepture-loss%E6%84%9F%E7%9F%A5%E9%A3%8E%E6%A0%BC%E6%8D%9F%E5%A4%B1"><span class="nav-text">1）Content
Percepture Loss 感知内容损失 &amp;&amp; Style Percepture
Loss感知风格损失</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#identity-loss"><span class="nav-text">2) Identity Loss</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%9C%80%E7%BB%88loss"><span class="nav-text">3）最终Loss</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Fantast"
      src="/images/avatar.webp">
  <p class="site-author-name" itemprop="name">Fantast</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">199</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">51</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">110</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/fantast416" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;fantast416" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:fantast416@gmail.com" title="E-Mail → mailto:fantast416@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <a href="https://www.zhihu.com/people/shuo-shuo-3-41" title="https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;shuo-shuo-3-41" rel="noopener" target="_blank">ZhiHu</a>
        </li>
        <li class="links-of-blogroll-item">
          <a href="http://www.next.zju.edu.cn/" title="http:&#x2F;&#x2F;www.next.zju.edu.cn&#x2F;" rel="noopener" target="_blank">NextLab</a>
        </li>
    </ul>
  </div>
        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://blog.fantast.top/2022/03/21/58ee25c0143c/">
    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.webp">
      <meta itemprop="name" content="Fantast">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Fantast's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          《StyTr2 Unbiased Image Style Transfer with Transformers》
        </h1>

        <div class="post-meta-container">
          
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2022-03-21 18:12:19" itemprop="dateCreated datePublished" datetime="2022-03-21T18:12:19+08:00">2022-03-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2022-11-19 18:43:51" itemprop="dateModified" datetime="2022-11-19T18:43:51+08:00">2022-11-19</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E2%91%A2-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index"><span itemprop="name">③  论文阅读笔记</span></a>
        </span>
          ，
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E2%91%A2-%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/CV%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87/" itemprop="url" rel="index"><span itemprop="name">CV相关论文</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
    <span class="post-meta-break"></span>
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>4k</span>
    </span>
    <span class="post-meta-item" title="阅读时长">
      <span class="post-meta-item-icon">
        <i class="far fa-clock"></i>
      </span>
      <span class="post-meta-item-text">阅读时长 &asymp;</span>
      <span>11 分钟</span>
    </span>
</div>

            <div class="post-description">提出了StyTr2，该框架中使用两个编码器来获取特定领域（Content & Style）的信息。在编码器之后，使用Transformer解码器逐步生成输出序列。</div>
            <div class="post-remind">Google Chrome is recommended, otherwise the image size may be wrong</div>
            <div class="post-remind">FireFox is not recommended,Because it does not support the image zoom property</div>
        </div>
        
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h4
id="论文名称stytr2-unbiased-image-style-transfer-with-transformers">论文名称：《StyTr^2
Unbiased Image Style Transfer with Transformers》</h4>
<h4 id="论文地址-httparxiv.orgabs2105.14576">论文地址：
http://arxiv.org/abs/2105.14576</h4>
<h2 id="关键词">1、关键词：</h2>
<p>​ Image Style Transfer、Transformer</p>
<h2 id="摘要">2、摘要：</h2>
<p>​
由于CNN的局部感知域性和空间不变性，输入图像的全局信息难以提取和维护。因此，传统的神经网络风格传递方法通常是有偏差的，对于同一幅参考风格图像，<strong>通过多次运行风格迁移过程可以观察到内容泄漏。</strong>为了解决这个关键问题，该文提出了一种基于Transformer的方法，即StyTr2，将输入图像的长期依赖关系考虑到无偏风格传输中。
​
与用于其他视觉任务的视觉转换器不同，我们的StyTr2包含两个不同的转换器编码器，分别为内容和样式生成特征序列。在编码器之后，采用多层Transformer解码器，根据样式序列对内容序列进行风格化。</p>
<h2 id="领域背景style-transfer">3、领域背景—Style Transfer：</h2>
<p>​
经典的基于深度学习的图像风格迁移，样式转换方法使用多层cnn来学习样式和内容表示。由于卷积层的接收域有限，CNN无法处理长距离依赖关系。输入图像难以获得全局信息，这是图像风格传递任务的关键。将Transformer应用于计算机视觉的魅力在于:</p>
<ul>
<li><ol type="1">
<li>它具有较强的表示能力，可以通过自注意机制自由地学习输入的全局信息，从而使每一层都能轻松获得整体的理解。</li>
</ol></li>
<li><ol start="2" type="1">
<li>Transformer不包含局部性和空间不变性引起的归纳偏差，可以避免风格传递任务中的内容泄漏</li>
</ol></li>
</ul>
<h2 id="先前工作描述与比较">4、先前工作描述与比较：</h2>
<p>​ 暂略</p>
<h2 id="主要设计思想">5、主要设计思想：</h2>
<p>​ 在StyTr2框架中使用两个编码器来获取特定领域（Content &amp;
Style）的信息。在编码器之后，使用Transformer解码器逐步生成输出序列。此外，针对自然语言处理中提出的位置编码方法，提出了两个方面的考虑:</p>
<ul>
<li><ol type="1">
<li>不同于按逻辑顺序排列的句子，图像序列符号是通过图像内容的语义信息进行关联的;</li>
</ol></li>
<li><ol start="2" type="1">
<li>对于风格迁移任务，目标是生成任意大小的风格化图像。输入图像大小的指数增长会导致位置编码的剧烈变化，从而导致较大的位置偏差和较差的输出质量。一般来说，视觉任务所需的位置编码应以输入内容为条件，而不受图像尺度变换的影响。</li>
</ol></li>
</ul>
<p>为此，该文还提出了<strong>基于图像语义特征的位置编码</strong>，并根据图像大小动态扩展位置编码。</p>
<p><strong>总结：主要贡献</strong></p>
<ul>
<li><ol type="a">
<li>一个基于Transformer的风格转换框架，即StyTr2，以减少内容泄漏并实现无偏的风格化;</li>
</ol></li>
<li><ol start="2" type="a">
<li>一种内容感知的位置编码机制，该机制是尺度不变的，适用于视觉生成任务;</li>
</ol></li>
</ul>
<h2 id="具体方法与网络架构">6、具体方法与网络架构：</h2>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321190212987.png" /></p>
<h3 id="图像分割为patches-linear-embedding与vit类似">1)
图像分割为Patches + Linear Embedding【与ViT类似】</h3>
<ul>
<li><strong>输入：</strong><span class="math inline">\(I_c \in R^{H
\times W \times 3}\)</span> 和 <span class="math inline">\(I_s \in R^{H
\times W \times 3}\)</span></li>
<li><strong>输出：</strong>一个特征序列：$ L C<span
class="math inline">\(，\)</span>L = $ ，<span
class="math inline">\(m\)</span>是PatchSize，<span
class="math inline">\(L\)</span>是特征序列tokens长度，<span
class="math inline">\(C\)</span>是单个Token的维度。</li>
</ul>
<h3 id="位置编码content-aware-positional-encoding">2) 位置编码（Content
Aware Positional Encoding）：</h3>
<ul>
<li><p><strong>想法：</strong>当使用基于Transformer的模型时，需要在输入序列中加入位置编码(PE)以获取结构信息。此论文提出了基于图像语义的位置编码，这一改进基于以下两个想法：</p></li>
<li><p>在传统的位置编码中：两个patch之间的位置相对关系仅仅与它们之间的距离有关。而对于图像生成任务，在计算位置编码时，我们应该考虑图像的语义</p></li>
<li><p>当输入图像的尺寸呈指数增长时，传统的正弦位置编码是否仍然适用于视觉任务?
如下所示当调整输入图像的大小时，相同语义的patches (blue
blocks)之间的相对关系会发生巨大的变化，这可能不适合视觉任务中多大小的输入。</p></li>
<li><p><strong>主要做法：</strong>提出了内容感知的位置编码(CAPE)，该编码具有<strong>尺度不变特性</strong>，更适合于风格迁移任务。与正弦PE只考虑Patches的相对距离不同，CAPE以图像内容语义为条件。</p></li>
<li><p>首先假设<span class="math inline">\(n \times n\)</span>
可以足够用于表示每幅图像的语义位置。</p></li>
<li><p>假设输入图像为：<span class="math inline">\(I \in R^{H \times W
\times 3}\)</span> ，我们将<span class="math inline">\(n \times
n\)</span>的位置编码（依据实验结果，一般情况下<span
class="math inline">\(n=18\)</span>），放缩至<span
class="math inline">\(L = \frac{H}{m} \times
\frac{W}{m}\)</span>的大小，这样就可以使得位置编码不受图像尺度的影响。即对于两个Image
Patches而言，它们直接的位置关系不会受到图像尺度的影响。如下图所示：假设有两个不同分辨率的图像，在PatchSize大小一样的情况下，左图分辨率小，被分割后，成为<span
class="math inline">\(2 \times 2\)</span>的Patch块，右图成为<span
class="math inline">\(4 \times
4\)</span>的Patch块。当位置编码会进行放缩以适应的时候，其就可以自己匹配不同尺度的图像。</p>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321210140364.png" /></p></li>
<li><p><strong>公式化表达</strong>：</p>
<ul>
<li><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321210523455.png" /></li>
<li><span class="math inline">\(P_{CA}(x,y)\)</span>代表第<span
class="math inline">\((x,y)\)</span>坐标的Patch的位置编码值</li>
<li><span
class="math inline">\(F_{pos}\)</span>是一个可学习的编码函数</li>
<li><span
class="math inline">\(P_L\)</span>是一个可学习的位置编码，是基于图像的token序列的</li>
<li><span class="math inline">\(a_{ij}\)</span>为插值权重，<span
class="math inline">\(s\)</span>是邻居的数量，其是由周围邻居加权差值计算得到的。</li>
<li>对于token序列<span
class="math inline">\(\epsilon\)</span>中的第i个Patch块，假设这个Patch块的坐标是<span
class="math inline">\((x,y)\)</span>，那么我们将计算得到的<span
class="math inline">\(P_{CAu}\)</span>值加到<span
class="math inline">\(\epsilon_i\)</span>中，形成最后的序列。即，如果原来的token序列<span
class="math inline">\(\epsilon\)</span>形状是<span
class="math inline">\(L \times C\)</span>，那么新的也应当为<span
class="math inline">\(L \times C\)</span></li>
</ul></li>
</ul>
<h3 id="transformer-encoder">3) Transformer Encoder：</h3>
<p>​ StyTr2有两个转换Encoder来编码特定于风格（内容图像 &amp;&amp;
风格图像）的特性，这些特性用于在下一阶段将序列从一个风格转换到另一个风格。</p>
<h4 id="part1-content-image">Part1: Content Image</h4>
<ul>
<li><strong>输入：</strong>Tokens 序列 <span class="math inline">\(Z_c
\in L \times C\)</span></li>
<li><strong>输出：</strong>$Y_c L C $</li>
<li><strong>网络结构：</strong>每个transformer encoder
layer包含一个MSA和一个FFN，与Transformer结构一致，输入序列被编码至Q，K，V。
<ul>
<li><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321215744833.png" /></li>
<li><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321215804639.png" /></li>
<li><span
class="math inline">\(W_q,W_k,W_v,W_o\)</span>是可学习参数矩阵。</li>
<li>然后使用残差连接结构，每个模块后有LN归一化</li>
<li><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321220112862.png" /></li>
</ul></li>
</ul>
<h4 id="part2-style-image">Part2: Style Image：</h4>
<p>​ 按照Content Image那样子进行处理，但是对于Style
Image我们<strong>不需要进行位置编码，因为我们不需要保持它的图像结构。</strong></p>
<ul>
<li><strong>输入：</strong>风格图像Tokens 序列 <span
class="math inline">\(Z_s \in L \times C\)</span></li>
<li><strong>输出：</strong>$Y_s L C $</li>
</ul>
<h3 id="transformer-decoder">4）Transformer Decoder：</h3>
<ul>
<li><strong>输入：</strong>$Y_c L C $ ， $Y_s L C $ （<span
class="math inline">\(\hat Y_c\)</span>是<span
class="math inline">\(Y_c\)</span>增加了CAPE位置编码后的序列）</li>
<li><strong>输出：</strong><span class="math inline">\(output \in
\frac{HW}{64} \times C\)</span></li>
</ul>
<p>​
根据参考的风格序列，用回归的方式来生成内容序列。和传统NLP任务不一样，我们使用序列中的所有Patches一次性输入来预测结果。</p>
<p><img src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321224013009.png" style="zoom: 80%;" /></p>
<p>​
由两个MSA和一个FNN模块组成。第一个MSA模块的K、V来源于Style序列，Q来源于Content序列。每个模块后面都有一个LN归一化。</p>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321232914140.png" /></p>
<ul>
<li><p>公式化表达：</p>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220321232959747.png" /></p></li>
</ul>
<h3 id="decoder">5）Decoder：</h3>
<p>​
论文使用了一个三层的CNN解码器来细化后面的Transformer解码器的输出，而不是直接对输出进行上采样来构造结果。</p>
<ul>
<li>输入：<span class="math inline">\(input \in \frac{HW}{64} \times
C\)</span></li>
<li>输出：<span class="math inline">\(I_{out} \in H \times W \times
3\)</span></li>
<li>网络结构组成：
<ul>
<li>$3 $ 卷积层</li>
<li>ReLU</li>
<li><span class="math inline">\(2 \times\)</span> 上采样操作</li>
</ul></li>
</ul>
<h2 id="采用的损失函数">7、采用的损失函数：</h2>
<h4
id="content-percepture-loss-感知内容损失-style-percepture-loss感知风格损失">1）Content
Percepture Loss 感知内容损失 &amp;&amp; Style Percepture
Loss感知风格损失</h4>
<p>​
优化结果应保持原有的内容结构，同时传递参考风格的模式。VGG提取的特征图可以作为内容特征来表示图像结构。<strong>Gram</strong>矩阵是两两向量的内积组成,所以<em>Gram</em>矩阵可以反映出该组向量中各个向量之间的某种关系。特征图的Gram矩阵可以作为风格特征来表示颜色、纹理等信息。因此，论文构建了<strong>感知内容损失</strong>来衡量生成图像<span
class="math inline">\(I_{cs}\)</span>与参考风格图像<span
class="math inline">\(I_c\)</span>之间的内容差异，构建<strong>感知风格损失</strong>来衡量生成图像<span
class="math inline">\(I_{cs}\)</span>与参考风格图像<span
class="math inline">\(I_s\)</span>之间的风格差异。</p>
<ul>
<li>Content Percepture Loss：</li>
</ul>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220322103100728.png" /></p>
<ul>
<li>Style Percepture Loss:</li>
</ul>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220322103340777.png" /></p>
<p>​ 因为神经网络各层的统计量(如均值和方差)包含了不同领域的特征。<span
class="math inline">\(\phi_i\)</span>代表使用预训练的VGG19网络，其第i层提取出的特征。<span
class="math inline">\(\mu()\)</span>代表特征的均值，<span
class="math inline">\(\sigma()\)</span>代表特征的方差。风格的感知损失可以书写如上。</p>
<h4 id="identity-loss">2) Identity Loss</h4>
<p>​
自监督学习可以利用PreText从大规模的非监督数据中挖掘其监督信息。网络可以用这种构造的监督信息进行训练，以学习下游任务的有价值表示。
论文采用一个辅助的<strong>自我风格迁移任务</strong>来学习更丰富、更准确的语义和风格表达。<strong>该任务具体操作如下：</strong></p>
<p>​
<strong>注</strong>：Pretext任务可以进一步理解为：<strong>对目标任务有帮助的辅助任务。</strong></p>
<p>​ 论文在StyTr2中输入两个相同的<span
class="math inline">\(内容/风格\)</span>图像，生成的图像<span
class="math inline">\(I_{cc}/I_{ss}\)</span>应该与输入图像<span
class="math inline">\(I_{c}/I_{s}\)</span>相同。因此，<span
class="math inline">\(Identity Loss\)</span>模拟<span
class="math inline">\(I_{c}/I_{s}\)</span>与<span
class="math inline">\(I_{cc}/I_{ss}\)</span>之间的差异:</p>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220322104028070.png" /></p>
<h4 id="最终loss">3）最终Loss</h4>
<p><img
src="https://mypic416.oss-cn-hangzhou.aliyuncs.com/windows/image-20220322104224116.png" /></p>
<p><span class="math inline">\(\lambda_c\)</span>、<span
class="math inline">\(\lambda_s\)</span>、<span
class="math inline">\(\lambda_{id1}\)</span>、<span
class="math inline">\(\lambda_{id2}\)</span> = { 10 , 7 , 50 , 1 }</p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相关文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2022\01\27\7d2ace115a28\" rel="bookmark">《UniFormer:Unifying Convolution and Self-attention for Visual Recognition》</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2021\12\20\cedd3c9597c5\" rel="bookmark">ML2021课程系列笔记3——卷积神经网络CNN</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2022\01\17\27fde64f6abc\" rel="bookmark">机器学习基础系列笔记8——图像风格迁移方法AdaIN</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2022\04\24\22e32ee5ba59\" rel="bookmark">《Not All Tokens Are Equal Human-centric Visual Analysis via Token Clustering Transformer》</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="\2022\04\24\503bff4618b7\" rel="bookmark">《Vision Transformer with Deformable Attention》</a></div>
    </li>
  </ul>


    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/CNN/" rel="tag"># CNN</a>
              <a href="/tags/Style-Transfer/" rel="tag"># Style Transfer</a>
              <a href="/tags/Transformer/" rel="tag"># Transformer</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/03/21/70cfb7bd8141/" rel="prev" title="关于文献综述、开题报告写作逻辑记录">
                  <i class="fa fa-chevron-left"></i> 关于文献综述、开题报告写作逻辑记录
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2022/03/25/9887f629bb62/" rel="next" title="2.2 处理机调度及相关算法">
                  2.2 处理机调度及相关算法 <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    <div class="comments utterances-container"></div>
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Fantast</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
    <span title="站点总字数">989k</span>
  </span>
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">45:49</span>
  </span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  
<script src="https://cdn.jsdelivr.net/npm/hexo-generator-searchdb@1.4.0/dist/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>





  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>


<script class="next-config" data-name="utterances" type="application/json">{"enable":true,"repo":"Fantast416/myblog-comment","issue_term":"pathname","theme":"github-light"}</script>
<script src="/js/third-party/comments/utterances.js"></script>

</body>
</html>
